{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "from tensorflow import keras\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "%config Completer.use_jedi =False\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import gensim\n",
    "from platform import python_version\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_embedding_array=np.load('picks_and_bans\\\\modified_embedding_array_30.npy')\n",
    "modified_names_array=np.load('picks_and_bans\\\\modified_names_array.npy')\n",
    "modified_pick_array=np.load('picks_and_bans\\\\modified_pick_array.npy')\n",
    "modified_bans_array=np.load('picks_and_bans\\\\modified_bans_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start=modified_embedding_array.shape[0]-int(0.05*modified_embedding_array.shape[0])\n",
    "cv_start=test_start-int(0.1*modified_embedding_array.shape[0])\n",
    "test_picks=modified_embedding_array[test_start:]\n",
    "testlabel_picks=modified_pick_array[test_start:]\n",
    "cv_picks=modified_embedding_array[cv_start:test_start]\n",
    "cvlabel_picks=modified_pick_array[cv_start:test_start]\n",
    "train_picks=modified_embedding_array[:cv_start]\n",
    "tlabel_picks=modified_pick_array[:cv_start]\n",
    "tlabel_picks=tlabel_picks.reshape((tlabel_picks.shape[0],tlabel_picks.shape[1],1))\n",
    "one_labels=tf.one_hot(tlabel_picks,depth=120)\n",
    "one_labels=tf.reshape(one_labels,(tlabel_picks.shape[0],tlabel_picks.shape[1],120))\n",
    "one_cvlabels=tf.one_hot(cvlabel_picks,depth=120)\n",
    "one_cvlabels=tf.reshape(one_cvlabels,(cvlabel_picks.shape[0],cvlabel_picks.shape[1],120))\n",
    "one_testlabels=tf.one_hot(testlabel_picks,depth=120)\n",
    "one_testlabels=tf.reshape(one_testlabels,(testlabel_picks.shape[0],testlabel_picks.shape[1],120))\n",
    "hero_df=pd.read_csv('hero_df.csv')\n",
    "hero_dict={}\n",
    "for i in hero_df['sid']:\n",
    "    hero_dict[i]=hero_df[hero_df['sid']==i]['localized_name'].values[0]\n",
    "embed_df=pd.read_csv('modified_hero_to_embedding.csv')\n",
    "embed_df.set_index('Heroes',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89385"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(arr,labels):\n",
    "\n",
    "    data=tf.data.Dataset.from_tensor_slices(arr)\n",
    "    vals=tf.data.Dataset.from_tensor_slices(labels)\n",
    "    combined=tf.data.Dataset.zip((data,vals))\n",
    "    finale=combined.map(lambda x,y: (x[:-1],y[-1]))\n",
    "    return finale\n",
    "def preds(arr):\n",
    "    if len(arr.shape)!=2:\n",
    "        data=tf.data.Dataset.from_tensor_slices(arr)\n",
    "        data=data.map(lambda x: x[:-1])\n",
    "        data=data.batch(1,drop_remainder=True)\n",
    "    else:\n",
    "        data=np.reshape(arr,(1,arr.shape[0],arr.shape[1]))\n",
    "        data=tf.data.Dataset.from_tensor_slices(data)\n",
    "        data=data.map(lambda x: x[:-1])\n",
    "        data=data.batch(1,drop_remainder=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pipe(train_picks,one_labels)\n",
    "train=train.batch(32,drop_remainder=True)\n",
    "cv=pipe(cv_picks,one_cvlabels)\n",
    "cv=cv.batch(1,drop_remainder=True)\n",
    "test=pipe(test_picks,one_testlabels)\n",
    "test=test.batch(1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2793/2793 [==============================] - 40s 14ms/step - loss: 4.1892 - top_k_categorical_accuracy: 0.1311 - val_loss: 4.0056 - val_top_k_categorical_accuracy: 0.1697\n",
      "Epoch 2/3\n",
      "2793/2793 [==============================] - 37s 13ms/step - loss: 3.9833 - top_k_categorical_accuracy: 0.1770 - val_loss: 3.9587 - val_top_k_categorical_accuracy: 0.1874\n",
      "Epoch 3/3\n",
      "2793/2793 [==============================] - 38s 14ms/step - loss: 3.8995 - top_k_categorical_accuracy: 0.1986 - val_loss: 3.9435 - val_top_k_categorical_accuracy: 0.1873\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential([\n",
    "    keras.layers.GRU(128,recurrent_dropout=0.25,return_sequences=True,input_shape=[None,30]),\n",
    "    keras.layers.GRU(128,recurrent_dropout=0.1),\n",
    "    keras.layers.Dense(120,activation='softmax'),\n",
    "    keras.layers.Lambda(lambda x: x/0.4)\n",
    "])\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(),optimizer=\"Nadam\",metrics=[keras.metrics.TopKCategoricalAccuracy(3)])\n",
    "history=model.fit(train,epochs=3,validation_data=cv)\n",
    "model.save('Models\\\\lstm128_30topk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('Models\\\\lstm128_30topk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the next best suggestion if any of the suggestions is a part of the bans list for that match\n",
    "y_pred=model.predict(test)\n",
    "y_true=[]\n",
    "for i in test:\n",
    "    y_true.append(i[1])\n",
    "y_true=np.array(y_true)\n",
    "y_true=y_true.reshape(y_true.shape[0]*y_true.shape[1],120)\n",
    "inbans=0\n",
    "modified_pred=np.copy(y_pred)\n",
    "for i,j in enumerate(modified_pred):\n",
    "    preds=np.argsort(-j)[:3]\n",
    "    while np.intersect1d(preds,modified_bans_array[i+test_start]).shape[0]!=0:\n",
    "        intersection=np.intersect1d(preds,modified_bans_array[i+test_start])\n",
    "        modified_pred[i,intersection]=-10.0\n",
    "        preds=np.argsort(-modified_pred[i])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.2587027>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk=keras.metrics.TopKCategoricalAccuracy(k=3)\n",
    "topk.update_state(y_true,modified_pred)\n",
    "topk.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
